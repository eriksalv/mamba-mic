{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from system import System\n",
    "from mamba_mic.data_modules.pi_caiv2 import PICAIV2DataModule\n",
    "from monai.inferers import sliding_window_inference\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Activations,\n",
    "    AsDiscreted,\n",
    "    Invertd,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    Lambdad,\n",
    "    MapTransform,\n",
    ")\n",
    "import monai.transforms as T\n",
    "from lightning.pytorch import seed_everything\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "System(\n",
       "  (net): DynUNet(\n",
       "    (input_block): UnetBasicBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(3, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    )\n",
       "    (downsamples): ModuleList(\n",
       "      (0): UnetBasicBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 1), stride=(2, 2, 1), padding=(1, 1, 0), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      )\n",
       "      (1): UnetBasicBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      )\n",
       "      (2): UnetBasicBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      )\n",
       "      (3): UnetBasicBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      )\n",
       "      (4): UnetBasicBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): UnetBasicBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    )\n",
       "    (upsamples): ModuleList(\n",
       "      (0): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(320, 320, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (2): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (3): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (4): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (5): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_block): UnetOutBlock(\n",
       "      (conv): Convolution(\n",
       "        (conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (skip_layers): DynUNetSkipLayer(\n",
       "      (downsample): UnetBasicBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(3, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      )\n",
       "      (next_layer): DynUNetSkipLayer(\n",
       "        (downsample): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(32, 64, kernel_size=(3, 3, 1), stride=(2, 2, 1), padding=(1, 1, 0), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "        (next_layer): DynUNetSkipLayer(\n",
       "          (downsample): UnetBasicBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "          (next_layer): DynUNetSkipLayer(\n",
       "            (downsample): UnetBasicBlock(\n",
       "              (conv1): Convolution(\n",
       "                (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "              )\n",
       "              (conv2): Convolution(\n",
       "                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "              )\n",
       "              (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            )\n",
       "            (next_layer): DynUNetSkipLayer(\n",
       "              (downsample): UnetBasicBlock(\n",
       "                (conv1): Convolution(\n",
       "                  (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "                )\n",
       "                (conv2): Convolution(\n",
       "                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                )\n",
       "                (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "                (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              )\n",
       "              (next_layer): DynUNetSkipLayer(\n",
       "                (downsample): UnetBasicBlock(\n",
       "                  (conv1): Convolution(\n",
       "                    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "                  )\n",
       "                  (conv2): Convolution(\n",
       "                    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                  )\n",
       "                  (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "                  (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                  (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                )\n",
       "                (next_layer): UnetBasicBlock(\n",
       "                  (conv1): Convolution(\n",
       "                    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 1), padding=(1, 1, 1), bias=False)\n",
       "                  )\n",
       "                  (conv2): Convolution(\n",
       "                    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                  )\n",
       "                  (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "                  (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                  (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                )\n",
       "                (upsample): UnetUpBlock(\n",
       "                  (transp_conv): Convolution(\n",
       "                    (conv): ConvTranspose3d(320, 320, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
       "                  )\n",
       "                  (conv_block): UnetBasicBlock(\n",
       "                    (conv1): Convolution(\n",
       "                      (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                    )\n",
       "                    (conv2): Convolution(\n",
       "                      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                    )\n",
       "                    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "                    (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                    (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (upsample): UnetUpBlock(\n",
       "                (transp_conv): Convolution(\n",
       "                  (conv): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "                )\n",
       "                (conv_block): UnetBasicBlock(\n",
       "                  (conv1): Convolution(\n",
       "                    (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                  )\n",
       "                  (conv2): Convolution(\n",
       "                    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                  )\n",
       "                  (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "                  (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                  (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (upsample): UnetUpBlock(\n",
       "              (transp_conv): Convolution(\n",
       "                (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "              )\n",
       "              (conv_block): UnetBasicBlock(\n",
       "                (conv1): Convolution(\n",
       "                  (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                )\n",
       "                (conv2): Convolution(\n",
       "                  (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "                )\n",
       "                (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "                (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "                (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (upsample): UnetUpBlock(\n",
       "            (transp_conv): Convolution(\n",
       "              (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "            )\n",
       "            (conv_block): UnetBasicBlock(\n",
       "              (conv1): Convolution(\n",
       "                (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "              )\n",
       "              (conv2): Convolution(\n",
       "                (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "              )\n",
       "              (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsample): UnetUpBlock(\n",
       "          (transp_conv): Convolution(\n",
       "            (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
       "          )\n",
       "          (conv_block): UnetBasicBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (upsample): UnetUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetBasicBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): DiceCELoss(\n",
       "    (dice): DiceLoss()\n",
       "    (cross_entropy): CrossEntropyLoss()\n",
       "    (binary_cross_entropy): BCEWithLogitsLoss()\n",
       "  )\n",
       "  (empty_criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = \"8d22yg6m\"\n",
    "checkpoint = \"model-epoch=224-val_dice=0.52\"\n",
    "checkpoint_path = f\"lightning_logs/{run_id}/checkpoints/{checkpoint}.ckpt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = System.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1499\n",
      "Training subjects: 1200\n",
      "Validation subjects: 150\n",
      "Test subjects: 149\n"
     ]
    }
   ],
   "source": [
    "data_module = PICAIV2DataModule(batch_size=1, include_empty_eval=True)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "val_set = data_module.val_set\n",
    "test_set = data_module.test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToBinaryLabeld(T.MapTransform):\n",
    "    def __init__(self, keys: list, invertible=True, allow_missing_keys=True):\n",
    "        self.keys = keys\n",
    "        self.invertible = invertible\n",
    "        self.allow_missing_keys = allow_missing_keys\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            if key in data:\n",
    "                label = d[key]  # Extract label tensor\n",
    "\n",
    "                if self.invertible:\n",
    "                    # Store the original label tensor for later inversion\n",
    "                    d[f\"original_{key}\"] = label.clone()\n",
    "\n",
    "                # Convert to binary: 0 for ISUP ≤1, 1 for ISUP ≥2\n",
    "                d[key] = (label >= 1).float()\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "def post_transforms(val_data):\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Invertd(\n",
    "                keys=\"pred\",\n",
    "                transform=data_module.preprocess,\n",
    "                orig_keys=\"label\",\n",
    "                meta_keys=\"pred_meta_dict\",\n",
    "                orig_meta_keys=\"image_meta_dict\",\n",
    "                meta_key_postfix=\"meta_dict\",\n",
    "                nearest_interp=True,\n",
    "                to_tensor=True,\n",
    "                device=\"cpu\",\n",
    "            ),\n",
    "            Invertd(\n",
    "                keys=\"label\",\n",
    "                transform=val_set.transform,\n",
    "                orig_keys=\"label\",\n",
    "                meta_keys=\"pred_meta_dict\",\n",
    "                orig_meta_keys=\"image_meta_dict\",\n",
    "                meta_key_postfix=\"meta_dict\",\n",
    "                nearest_interp=False,\n",
    "                to_tensor=True,\n",
    "                device=\"cpu\",\n",
    "            ),\n",
    "            ConvertToBinaryLabeld(keys=[\"label\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply transformations\n",
    "    val_data = transform(val_data)\n",
    "    sigmoid = Activations(sigmoid=True)\n",
    "    val_data[\"pred\"] = sigmoid(val_data[\"pred\"])\n",
    "    return val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(\n",
    "    t2w_img, ground_truth, prediction, title=\"Segmentation Visualization\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to visualize ground truth and predicted segmentation overlays on the T2W image.\n",
    "\n",
    "    Parameters:\n",
    "    - t2w_img (numpy array): The grayscale T2-weighted image.\n",
    "    - ground_truth (numpy array): Ground truth segmentation mask.\n",
    "    - prediction (numpy array): Predicted segmentation mask.\n",
    "    - title (str): Title for the visualization.\n",
    "    \"\"\"\n",
    "    # Find the slice with the most segmentation in the ground truth\n",
    "    label_slices = np.sum(ground_truth, axis=(0, 1))  # Sum over H, W\n",
    "    slice_idx = np.argmax(label_slices)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    if t2w_img is not None:\n",
    "        axes[0].imshow(t2w_img[:, :, slice_idx], cmap=\"gray\")\n",
    "        axes[0].imshow(ground_truth[:, :, slice_idx], cmap=\"Reds\", alpha=0.8)\n",
    "        axes[0].axis(\"off\")\n",
    "    else:\n",
    "        axes[0].imshow(ground_truth[:, :, slice_idx], cmap=\"Reds\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "    if t2w_img is not None:\n",
    "        axes[1].imshow(t2w_img[:, :, slice_idx], cmap=\"gray\")\n",
    "        confidence_map = axes[1].imshow(\n",
    "            prediction[:, :, slice_idx], cmap=\"coolwarm\", vmin=0, vmax=1, alpha=0.6\n",
    "        )\n",
    "        axes[1].axis(\"off\")\n",
    "    else:\n",
    "        confidence_map = axes[1].imshow(\n",
    "            prediction[:, :, slice_idx], cmap=\"coolwarm\", vmin=0, vmax=1\n",
    "        )\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "    fig.colorbar(\n",
    "        confidence_map, ax=axes[1], fraction=0.046, pad=0.04, label=\"Confidence (0-1)\"\n",
    "    )\n",
    "\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 150/150 [5:17:59<00:00, 127.20s/it]  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "\n",
    "show_seg = False\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for val_data in tqdm(val_set):\n",
    "        path = val_data[\"label\"].meta[\"filename_or_obj\"]\n",
    "        filename = os.path.basename(path)  # Get filename from full path\n",
    "        case_id = \"_\".join(filename.split(\"_\")[:2])\n",
    "\n",
    "        case_label_dir = f\"./data/PICCAIv2/labels/val/{case_id}\"\n",
    "        case_pred_dir = f\"./data/PICCAIv2/predictions/val/{case_id}\"\n",
    "\n",
    "        # Define paths to label and prediction files\n",
    "        label_path = f\"{case_label_dir}/{run_id}_{checkpoint}_val.nii.gz\"\n",
    "        pred_path = f\"{case_pred_dir}/{run_id}_{checkpoint}_val.nii.gz\"\n",
    "\n",
    "        # Check if the files already exist to avoid reprocessing\n",
    "        # if os.path.exists(label_path) and os.path.exists(pred_path):\n",
    "        #    print(f\"Skipping case {case_id} as predictions already exist.\")\n",
    "        #    continue\n",
    "\n",
    "        x, y = (\n",
    "            val_data[\"image\"].to(device).unsqueeze(0),\n",
    "            val_data[\"label\"].to(device).unsqueeze(0),\n",
    "        )\n",
    "        val_data[\"pred\"] = sliding_window_inference(\n",
    "            x, roi_size=[256, 256, 32], overlap=0.5, sw_batch_size=3, predictor=model\n",
    "        ).squeeze(0)\n",
    "\n",
    "        postprocessed = post_transforms(val_data)\n",
    "\n",
    "        y_pred = torch.tensor(postprocessed[\"pred\"])\n",
    "        y = torch.tensor(postprocessed[\"label\"])\n",
    "\n",
    "        if show_seg:\n",
    "            y_pred_np, y_true_np = postprocessed[\"pred\"], postprocessed[\"label\"]\n",
    "\n",
    "            y_true_np = y_true_np.squeeze()\n",
    "            y_pred_np = y_pred_np.squeeze()\n",
    "\n",
    "            visualize_segmentation(\n",
    "                None, y_true_np, y_pred_np, title=\"Post-Processed Segmentation\"\n",
    "            )\n",
    "\n",
    "        os.makedirs(case_label_dir, exist_ok=True)\n",
    "        os.makedirs(case_pred_dir, exist_ok=True)\n",
    "\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                y_pred.type(torch.float).numpy(),\n",
    "                affine=val_data[\"image\"].meta[\"original_affine\"],\n",
    "            ),\n",
    "            f\"{case_pred_dir}/{run_id}_{checkpoint}_val.nii.gz\",\n",
    "        )\n",
    "\n",
    "        # TODO doesnt need to be saved for each model, add check\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                y.type(torch.float).numpy(),\n",
    "                affine=val_data[\"image\"].meta[\"original_affine\"],\n",
    "            ),\n",
    "            f\"{case_label_dir}/{run_id}_{checkpoint}_val.nii.gz\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 10/10 [20:58<00:00, 125.86s/it]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "\n",
    "show_seg = False\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_data in tqdm(test_set):\n",
    "        path = test_data[\"label\"].meta[\"filename_or_obj\"]\n",
    "        filename = os.path.basename(path)  # Get filename from full path\n",
    "        case_id = \"_\".join(filename.split(\"_\")[:2])\n",
    "\n",
    "        case_label_dir = f\"./data/PICCAIv2/labels/test/{case_id}\"\n",
    "        case_pred_dir = f\"./data/PICCAIv2/predictions/test/{case_id}\"\n",
    "\n",
    "        # Define paths to label and prediction files\n",
    "        label_path = f\"{case_label_dir}/{run_id}_{checkpoint}_test.nii.gz\"\n",
    "        pred_path = f\"{case_pred_dir}/{run_id}_{checkpoint}_test.nii.gz\"\n",
    "\n",
    "        # Check if the files already exist to avoid reprocessing\n",
    "        # if os.path.exists(label_path) and os.path.exists(pred_path):\n",
    "        #    print(f\"Skipping case {case_id} as predictions already exist.\")\n",
    "        #    continue\n",
    "\n",
    "        x, y = (\n",
    "            test_data[\"image\"].to(device).unsqueeze(0),\n",
    "            test_data[\"label\"].to(device).unsqueeze(0),\n",
    "        )\n",
    "        test_data[\"pred\"] = sliding_window_inference(\n",
    "            x, roi_size=[256, 256, 32], overlap=0.5, sw_batch_size=3, predictor=model\n",
    "        ).squeeze(0)\n",
    "\n",
    "        postprocessed = post_transforms(test_data)\n",
    "        y_pred = torch.tensor(postprocessed[\"pred\"])\n",
    "        y = torch.tensor(postprocessed[\"label\"])\n",
    "\n",
    "        if show_seg:\n",
    "            y_pred_np, y_true_np = postprocessed[\"pred\"], postprocessed[\"label\"]\n",
    "\n",
    "            y_true_np = y_true_np.squeeze()\n",
    "            y_pred_np = y_pred_np.squeeze()\n",
    "\n",
    "            visualize_segmentation(\n",
    "                None, y_true_np, y_pred_np, title=\"Post-Processed Segmentation\"\n",
    "            )\n",
    "\n",
    "        os.makedirs(case_label_dir, exist_ok=True)\n",
    "        os.makedirs(case_pred_dir, exist_ok=True)\n",
    "\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                y_pred.type(torch.float).numpy(),\n",
    "                affine=test_data[\"image\"].meta[\"original_affine\"],\n",
    "            ),\n",
    "            f\"{case_pred_dir}/{run_id}_{checkpoint}_test.nii.gz\",\n",
    "        )\n",
    "\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                y.type(torch.float).numpy(),\n",
    "                affine=test_data[\"image\"].meta[\"original_affine\"],\n",
    "            ),\n",
    "            f\"{case_label_dir}/{run_id}_{checkpoint}_test.nii.gz\",\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
